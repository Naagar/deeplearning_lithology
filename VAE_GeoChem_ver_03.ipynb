{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_GeoChem_ver_02.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPRR3YBeUX0B"
      },
      "source": [
        "# Library for the Satellite images\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZWbrKfqTaVT"
      },
      "source": [
        "## Bands\n",
        "ToDo: Single band <- 7 bands,\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffeUiGKpmR2q"
      },
      "source": [
        "!pip install earthpy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq2r9CG2PofR",
        "outputId": "f5e10505-0070-4f8f-8de5-4b4b8167d2f7"
      },
      "source": [
        "pip install pyrsgis==0.3.9"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyrsgis==0.3.9 in /usr/local/lib/python3.7/dist-packages (0.3.9)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja9_SikbUp7_"
      },
      "source": [
        "## Data Prepration and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_l7ZaIl3a64g",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9d1a4e8-4302-4aac-fa20-2f741e113ab1"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "# import sklearn\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromArray\n",
        "\n",
        "# Defining file names\n",
        "featureFile = 'Playa_Image.tif'\n",
        "# labelFile = 'Playa_Image_Training.tif'\n",
        "\n",
        "# Reading and normalizing input data\n",
        "dsFeatures, arrFeatures = raster.read(featureFile, bands='all')\n",
        "arrFeatures = arrFeatures.astype(float)\n",
        "\n",
        "for i in range(arrFeatures.shape[0]):\n",
        "    bandMin = arrFeatures[i][:][:].min()\n",
        "    bandMax = arrFeatures[i][:][:].max()\n",
        "    bandRange = bandMax-bandMin\n",
        "    for j in range(arrFeatures.shape[1]):\n",
        "        for k in range(arrFeatures.shape[2]):\n",
        "            arrFeatures[i][j][k] = (arrFeatures[i][j][k]-bandMin)/bandRange\n",
        "\n",
        "# Creating chips using pyrsgis\n",
        "features = imageChipsFromArray(arrFeatures, x_size=7, y_size=7)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning! matplotlib_scalebar library not found. You may not be able to export map directly.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bkQQ6a8La02b"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromArray, imageChipsFromFile\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "# Defining the function to split features and labels\n",
        "def train_test_split(features,  trainProp=0.75):\n",
        "    dataSize = features.shape[0]\n",
        "    sliceIndex = int(dataSize*trainProp)\n",
        "    randIndex = np.arange(dataSize)\n",
        "    random.shuffle(randIndex)\n",
        "    train_x = features[[randIndex[:sliceIndex]], :, :, :][0]\n",
        "    test_x = features[[randIndex[sliceIndex:]], :, :, :][0]\n",
        "    # train_y = labels[randIndex[:sliceIndex]]\n",
        "    # test_y = labels[randIndex[sliceIndex:]]\n",
        "    return(train_x,  test_x, )\n",
        "\n",
        "# Calling the function to split the data\n",
        "train_x, test_x = train_test_split(features)"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e-4pPsHVbSC7"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gH-0O7R5bUhZ"
      },
      "source": [
        "data_loader = torch.utils.data.DataLoader(train_x,\n",
        "                                          batch_size=32,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)\n"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mwkJuBxeLRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de5b7a4f-dbad-423b-d396-1108decfdad1"
      },
      "source": [
        "# mnist_data = MNIST(root='./', download=True, transform=transforms.ToTensor())\n",
        "import matplotlib.pyplot as plt\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromArray, imageChipsFromFile\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# read the TIF file(s) (both are of different sizes - for demonstration)\n",
        "single_band_file = r'Playa_Image.tif' # this is a Landsat 5 TM image (7 bands stacked)\n",
        "# multi_band_file = r'Playa_Image.tif' # this is a Landsat 5 TM image (7 bands stacked)\n",
        "\n",
        "# create image chips\n",
        "single_band_chips = imageChipsFromFile(single_band_file, x_size=28, y_size=28)\n",
        "# multi_band_chips = imageChipsFromFile(multi_band_file, x_size=16, y_size=16)\n",
        "\n",
        "print(single_band_chips.shape)\n",
        "# print(multi_band_chips.shape)\n",
        "print(single_band_chips[1].shape)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(189658, 28, 28, 7)\n",
            "(28, 28, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "duwvNyewQ1eH",
        "outputId": "de379f3e-19d0-44f2-d9f1-7af7c27a949e"
      },
      "source": [
        "print(len(single_band_chips))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "189658\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr1pdMckVXA4"
      },
      "source": [
        "## Change datatype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzqEYVArlgXA",
        "outputId": "90239c6e-7648-4efa-9c35-425e08700b97"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 \n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# changin the type of data images \n",
        "single_band_chips        = np.rollaxis(single_band_chips, 3, 1)\n",
        "single_band_chips_float  = single_band_chips.astype(np.float32)\n",
        "\n",
        "single_band_chips_tensor = torch.as_tensor(single_band_chips_float)\n",
        "\n",
        "print(single_band_chips_tensor.dtype)\n",
        "\n",
        "print('no of chips: bends: h: W ',single_band_chips.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "no of chips: bends: h: W  (189658, 7, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb4WliqwbIw1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from utils import ACTIVATION_DERIVATIVES\n",
        "import math\n",
        "import torch\n",
        "# from flows import RadialFlow, PlanarFlow\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "# from models import FCNEncoder, FCNDecoder, FlowModel\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.special import logsumexp\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "from matplotlib import collections  as mc"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89vFZ8hPU-cW"
      },
      "source": [
        "## VAE Flow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC-FuVB4BqzF"
      },
      "source": [
        "from typing import List\n",
        "class FCNEncoder(nn.Module):\n",
        "    def __init__(self, hidden_sizes: List[int], dim_input: int, activation=nn.ReLU()):\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        hidden_sizes = [dim_input] + hidden_sizes\n",
        "        \n",
        "        self.net = []\n",
        "\n",
        "        for i in range(len(hidden_sizes) - 1):\n",
        "            self.net.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
        "            self.net.append(nn.ReLU())\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMmIV6CCagnw"
      },
      "source": [
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "class FlowModel(nn.Module):\n",
        "    def __init__(self, flows: List[str], D: int, activation=torch.tanh):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.prior = MultivariateNormal(torch.zeros(D), torch.eye(D))\n",
        "        self.net = []\n",
        "\n",
        "        for i in range(len(flows)):\n",
        "            layer_class = eval(flows[i])\n",
        "            self.net.append(layer_class(D, activation))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "        self.D = D\n",
        "\n",
        "\n",
        "    def forward(self, mu: torch.Tensor, log_sigma: torch.Tensor):\n",
        "        \"\"\"\n",
        "        mu: tensor with shape (batch_size, D)\n",
        "        sigma: tensor with shape (batch_size, D)\n",
        "        \"\"\"\n",
        "        sigma = torch.exp(log_sigma)\n",
        "        batch_size = mu.shape[0]\n",
        "        samples = self.prior.sample(torch.Size([batch_size]))\n",
        "        # print(samples.size, sigma.shape)\n",
        "        z = samples * sigma + mu\n",
        "\n",
        "        z0 = z.clone().detach()\n",
        "        log_prob_z0 = torch.sum(\n",
        "            -0.5 * torch.log(torch.tensor(2 * math.pi)) - \n",
        "            log_sigma - 0.5 * ((z - mu) / sigma) ** 2, \n",
        "            axis=1)\n",
        "        \n",
        "        log_det = torch.zeros((batch_size,))\n",
        "        \n",
        "        for layer in self.net:\n",
        "            z, ld = layer(z)\n",
        "            log_det += ld\n",
        "\n",
        "        log_prob_zk = torch.sum(\n",
        "            -0.5 * (torch.log(torch.tensor(2 * math.pi)) + z ** 2), \n",
        "            axis=1)\n",
        "\n",
        "        return z, log_prob_z0, log_prob_zk, log_det"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWl5ZQMXfoeq"
      },
      "source": [
        "ACTIVATION_DERIVATIVES = {\n",
        "    F.elu: lambda x: torch.ones_like(x) * (x >= 0) + torch.exp(x) * (x < 0),\n",
        "    torch.tanh: lambda x: 1 - torch.tanh(x) ** 2\n",
        "}\n",
        "\n",
        "class PlanarFlow(nn.Module):\n",
        "    def __init__(self, D, activation=torch.tanh):\n",
        "        super().__init__()\n",
        "        self.D = D\n",
        "        self.w = nn.Parameter(torch.empty(D))\n",
        "        self.b = nn.Parameter(torch.empty(1))\n",
        "        self.u = nn.Parameter(torch.empty(D))\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = ACTIVATION_DERIVATIVES[activation]\n",
        "\n",
        "        nn.init.normal_(self.w)\n",
        "        nn.init.normal_(self.u)\n",
        "        nn.init.normal_(self.b)\n",
        "\n",
        "    def forward(self, z: torch.Tensor):\n",
        "        lin = (z @ self.w + self.b).unsqueeze(1)  # shape: (B, 1)\n",
        "        f = z + self.u * self.activation(lin)  # shape: (B, D)\n",
        "        phi = self.activation_derivative(lin) * self.w  # shape: (B, D)\n",
        "        log_det = torch.log(torch.abs(1 + phi @ self.u) + 1e-4) # shape: (B,)\n",
        "        \n",
        "\n",
        "        return f, log_det\n",
        "\n",
        "\n",
        "class RadialFlow(nn.Module):\n",
        "    def __init__(self, D, activation=torch.tanh):\n",
        "        super().__init__()\n",
        "\n",
        "        self.z0 = nn.Parameter(torch.empty(D))\n",
        "        self.log_alpha = nn.Parameter(torch.empty(1))\n",
        "        self.beta = nn.Parameter(torch.empty(1))\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = ACTIVATION_DERIVATIVES[activation]\n",
        "        self.D = D\n",
        "\n",
        "        nn.init.normal_(self.z0) \n",
        "        nn.init.normal_(self.log_alpha)\n",
        "        nn.init.normal_(self.beta)\n",
        "\n",
        "\n",
        "    def forward(self, z: torch.Tensor):\n",
        "        z_sub = z - self.z0\n",
        "        alpha = torch.exp(self.log_alpha)\n",
        "        r = torch.norm(z_sub)\n",
        "        h = 1 / (alpha + r)\n",
        "        f = z + self.beta * h * z_sub\n",
        "        log_det = (self.D - 1) * torch.log(1 + self.beta * h) + \\\n",
        "            torch.log(1 + self.beta * h + self.beta - self.beta * r / (alpha + r) ** 2)\n",
        "\n",
        "        return f, log_det"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rrThVTZah_O"
      },
      "source": [
        "class FCNDecoder(nn.Module):\n",
        "    def __init__(self, hidden_sizes: List[int], dim_input: int, activation=nn.ReLU()):\n",
        "        super().__init__()\n",
        "        \n",
        "        hidden_sizes = [dim_input] + hidden_sizes\n",
        "        self.net = []\n",
        "\n",
        "        for i in range(len(hidden_sizes) - 1):\n",
        "            self.net.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
        "            self.net.append(nn.ReLU())\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, z: torch.Tensor):\n",
        "        return self.net(z)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZcOrS_EeT1S"
      },
      "source": [
        "D = 40 # Depth (No. of channels)\n",
        "encoder = FCNEncoder(hidden_sizes=[128, 64, 2*D], dim_input=7*7*7)\n",
        "flow_model = FlowModel(flows=['PlanarFlow'] * 10, D=40)\n",
        "decoder = FCNDecoder(hidden_sizes=[64, 128, 343], dim_input=40)\n",
        "# optimizer Adam\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(flow_model.parameters()) + list(decoder.parameters()))"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-4VQKkJWAWf"
      },
      "source": [
        "## Training of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A1VLVA_iV-yB",
        "outputId": "0225f152-ec60-4dda-978a-97b9ea0df51d"
      },
      "source": [
        "loss_fn = BCEWithLogitsLoss()\n",
        "running_loss = []\n",
        "for i, X_batch in enumerate(data_loader):\n",
        "    optimizer.zero_grad()\n",
        "    out = encoder(X_batch.view(-1, 7*49).float())\n",
        "    mu, log_sigma = out[:, :40], out[:, 40:]\n",
        "    z_k, log_prob_z0, log_prob_zk, log_det = flow_model(mu, log_sigma)\n",
        "    x_hat = decoder(z_k)\n",
        "    # print(x_hat.shape)\n",
        "    # print(X_batch.shape)\n",
        "    \n",
        "    loss = torch.mean(log_prob_z0) + loss_fn(x_hat, X_batch.view(-1, 343).float()) - torch.mean(log_prob_zk) - torch.mean(log_det)\n",
        "    if i % 100 == 0:\n",
        "        print(f'Iteration {i}, loss: {loss.item()}')\n",
        "        running_loss.append(loss)\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, loss: 219.13465881347656\n",
            "Iteration 100, loss: 170.40640258789062\n",
            "Iteration 200, loss: 141.54542541503906\n",
            "Iteration 300, loss: 111.38267517089844\n",
            "Iteration 400, loss: 89.8583984375\n",
            "Iteration 500, loss: 79.28489685058594\n",
            "Iteration 600, loss: 73.37884521484375\n",
            "Iteration 700, loss: 60.26276779174805\n",
            "Iteration 800, loss: 50.16343307495117\n",
            "Iteration 900, loss: 49.55780792236328\n",
            "Iteration 1000, loss: 49.9427490234375\n",
            "Iteration 1100, loss: 45.19700622558594\n",
            "Iteration 1200, loss: 39.487762451171875\n",
            "Iteration 1300, loss: 34.3146858215332\n",
            "Iteration 1400, loss: 42.74226760864258\n",
            "Iteration 1500, loss: 33.17182159423828\n",
            "Iteration 1600, loss: 24.305044174194336\n",
            "Iteration 1700, loss: 16.43391990661621\n",
            "Iteration 1800, loss: 15.894693374633789\n",
            "Iteration 1900, loss: 13.634346961975098\n",
            "Iteration 2000, loss: 9.947776794433594\n",
            "Iteration 2100, loss: 24.665428161621094\n",
            "Iteration 2200, loss: 14.912765502929688\n",
            "Iteration 2300, loss: 9.133270263671875\n",
            "Iteration 2400, loss: 6.57927131652832\n",
            "Iteration 2500, loss: 15.191566467285156\n",
            "Iteration 2600, loss: 9.654356002807617\n",
            "Iteration 2700, loss: 10.164485931396484\n",
            "Iteration 2800, loss: 12.006585121154785\n",
            "Iteration 2900, loss: 9.710370063781738\n",
            "Iteration 3000, loss: 11.234848022460938\n",
            "Iteration 3100, loss: 6.899669170379639\n",
            "Iteration 3200, loss: 2.082028865814209\n",
            "Iteration 3300, loss: 3.3881101608276367\n",
            "Iteration 3400, loss: 7.717289924621582\n",
            "Iteration 3500, loss: 3.410220146179199\n",
            "Iteration 3600, loss: 2.867922306060791\n",
            "Iteration 3700, loss: 6.606855869293213\n",
            "Iteration 3800, loss: 2.969198226928711\n",
            "Iteration 3900, loss: 4.755001544952393\n",
            "Iteration 4000, loss: 12.472825050354004\n",
            "Iteration 4100, loss: 2.900674819946289\n",
            "Iteration 4200, loss: 3.036630868911743\n",
            "Iteration 4300, loss: 6.423008441925049\n",
            "Iteration 4400, loss: 2.0829625129699707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 282
        },
        "id": "zdc3jgAiU0SF",
        "outputId": "4bdacbeb-5b78-4b05-e54e-e9a28f2ce31e"
      },
      "source": [
        "plt.plot(running_loss)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7f9aadab2dd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 28
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFJS90wZayY9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "41b919bd-722a-44c6-f1de-3b9cec9c3de5"
      },
      "source": [
        "out = encoder(X_batch.view(-1, 343).float())\n",
        "mu, log_sigma = out[:, :D], out[:, D:]\n",
        "z_k, log_prob_z0, log_prob_zk, log_det = flow_model(mu, log_sigma)\n",
        "x_hat = decoder(z_k)\n",
        "\n",
        "loss = torch.mean(log_prob_z0) + loss_fn(x_hat, X_batch.view(-1, 343).float()) - torch.mean(log_prob_zk) - torch.mean(log_det)\n",
        "print(loss)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(2.0599, grad_fn=<SubBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZRa2o5KXbRi"
      },
      "source": [
        "# Trash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jZgLUOg4ZZl8"
      },
      "source": [
        "import numpy as np\n",
        "import random\n",
        "# import sklearn\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromArray\n",
        "\n",
        "# Defining file names\n",
        "featureFile = 'Playa_Image.tif'\n",
        "# labelFile = 'Playa_Image_Training.tif'\n",
        "\n",
        "# Reading and normalizing input data\n",
        "dsFeatures, arrFeatures = raster.read(featureFile, bands='all')\n",
        "arrFeatures = arrFeatures.astype(float)\n",
        "\n",
        "for i in range(arrFeatures.shape[0]):\n",
        "    bandMin = arrFeatures[i][:][:].min()\n",
        "    bandMax = arrFeatures[i][:][:].max()\n",
        "    bandRange = bandMax-bandMin\n",
        "    for j in range(arrFeatures.shape[1]):\n",
        "        for k in range(arrFeatures.shape[2]):\n",
        "            arrFeatures[i][j][k] = (arrFeatures[i][j][k]-bandMin)/bandRange\n",
        "\n",
        "# Creating chips using pyrsgis\n",
        "features = imageChipsFromArray(arrFeatures, x_size=7, y_size=7)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q02JFN0zZniI",
        "outputId": "d6ec1128-d51f-4902-98f5-ae3ccfe6a4f5"
      },
      "source": [
        "print(features.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(188788, 7, 7, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EbF_JcUsZ-qM"
      },
      "source": [
        "# Defining the function to split features and labels\n",
        "def train_test_split(features,  trainProp=0.75):\n",
        "    dataSize = features.shape[0]\n",
        "    sliceIndex = int(dataSize*trainProp)\n",
        "    randIndex = np.arange(dataSize)\n",
        "    random.shuffle(randIndex)\n",
        "    train_x = features[[randIndex[:sliceIndex]], :, :, :][0]\n",
        "    test_x = features[[randIndex[sliceIndex:]], :, :, :][0]\n",
        "    # train_y = labels[randIndex[:sliceIndex]]\n",
        "    # test_y = labels[randIndex[sliceIndex:]]\n",
        "    return(train_x,  test_x, )\n",
        "\n",
        "# Calling the function to split the data\n",
        "train_x, test_x = train_test_split(features)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qIhjJdhaeTI",
        "outputId": "25c289bb-ead6-4c59-8ba1-23eb6314de81"
      },
      "source": [
        "print(train_x.shape, test_x.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(141591, 7, 7, 7) (47197, 7, 7, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQz_3vJdZZc"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BinarizedMNIST(Dataset):\n",
        "    def __init__(self, file):\n",
        "        self.data = np.load(file)\n",
        "        self.data = torch.tensor(self.data)\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# mnist_data = MNIST(root='./', download=True, transform=transforms.ToTensor())\n",
        "# data = BinarizedMNIST(single_band_chips)\n",
        "data_loader = torch.utils.data.DataLoader(single_band_chips_tensor,\n",
        "                                          batch_size=32,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvdobDaAYTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cf8f95-428b-4925-b725-89100bbe4483"
      },
      "source": [
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromArray, imageChipsFromFile\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "# read the TIF file(s) (both are of different sizes - for demonstration)\n",
        "single_band_file = r'Playa_Image.tif'\n",
        "multi_band_file = r'Playa_Image.tif' # this is a Landsat 7 TM image (7 bands stacked)\n",
        "\n",
        "# create image chips\n",
        "single_band_chips = imageChipsFromFile(single_band_file, x_size=16, y_size=16)\n",
        "multi_band_chips  = imageChipsFromFile(multi_band_file, x_size=16, y_size=16)\n",
        "\n",
        "print(single_band_chips.shape)\n",
        "print(multi_band_chips.shape)\n",
        "# # read the files as array using pyrsgis raster.read module\n",
        "# _, single_band_array = raster.read(single_band_file)\n",
        "# _, multi_band_array = raster.read(multi_band_file)\n",
        "\n",
        "# # create image chips\n",
        "# single_band_chips = imageChipsFromArray(single_band_array, x_size=5, y_size=5)\n",
        "# multi_band_chips  = imageChipsFromArray(multi_band_array, x_size=5, y_size=5)\n",
        "\n",
        "# print(single_band_chips.shape)\n",
        "# print(multi_band_chips.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning! matplotlib_scalebar library not found. You may not be able to export map directly.\n",
            "(189658, 16, 16, 7)\n",
            "(189658, 16, 16, 7)\n"
          ]
        }
      ]
    }
  ]
}