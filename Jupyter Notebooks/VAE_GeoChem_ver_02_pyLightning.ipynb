{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_GeoChem_ver_02_pyLightning.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P4BHjEet7jV_"
      },
      "source": [
        "#  VAE for Cifar10\n",
        "15/11/2021"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "ZKDYEL4H7na3",
        "outputId": "24afebcc-4c2a-4dd9-bcc1-e51a7c7246b4"
      },
      "source": [
        "pip3 install pytorch-lightning-bolts\n",
        "pip3 install pytorch-lightning-bolts==0.2.5rc1"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-15-938370b0a44f>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip3 install pytorch-lightning-bolts\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "w8Pn_Zl29wLU",
        "outputId": "ac36832b-a386-40e6-b6c3-181dc7838dbd"
      },
      "source": [
        "pip install pytorch-lightning==1.0.8\n",
        "pip install pytorch-lightning-bolts==0.2.5rc1"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-11-b812aa22c023>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    pip install pytorch-lightning==1.0.8\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FVJdngbW-KEv"
      },
      "source": [
        "pip install pytorch-lightning==1.0.8"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1MYlhKU--SJf",
        "outputId": "0c8c8d18-59e9-4169-865e-2a9408c41b4f"
      },
      "source": [
        "pip install pytorch-lightning-bolts==0.2.5rc1"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement pytorch-lightning-bolts==0.2.5rc1 (from versions: 0.1.0, 0.1.1, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.3.0, 0.3.1, 0.3.2)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for pytorch-lightning-bolts==0.2.5rc1\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 129
        },
        "id": "r3fwKFO-7y4z",
        "outputId": "2c823874-f7ba-4a2d-b3ab-dce7d20907f5"
      },
      "source": [
        "pytorch-lightning-bolts"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-19-d34441a412ca>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    from pytorch-lightning-bolts.models.autoencoders import VAE\u001b[0m\n\u001b[0m                ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5c2DU_Y77wT"
      },
      "source": [
        "## ELBO loss\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "78wc_gIv76IX"
      },
      "source": [
        "kl = torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim = 1), dim = 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7GCE6Ca8PEN"
      },
      "source": [
        "def kl_divergence(self, z, mu, std):\n",
        "    # --------------------------\n",
        "    # Monte carlo KL divergence\n",
        "    # --------------------------\n",
        "    # 1. define the first two probabilities (in this case Normal for both)\n",
        "    p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
        "    q = torch.distributions.Normal(mu, std)\n",
        "\n",
        "    # 2. get the probabilities from the equation\n",
        "    log_qzx = q.log_prob(z)\n",
        "    log_pz = p.log_prob(z)\n",
        "\n",
        "    # kl\n",
        "    kl = (log_qzx - log_pz)\n",
        "    \n",
        "    # sum over last dim to go from single dim distribution to multi-dim\n",
        "    kl = kl.sum(-1)\n",
        "    return kl"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5tbpiWEK8Py9"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5JI5AnT68dvd"
      },
      "source": [
        "## Define VAE "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 374
        },
        "id": "DNmostaf8be1",
        "outputId": "09905483-874e-48b0-e413-db46a237a90b"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "from torch import nn\n",
        "import torch\n",
        "from pl_bolts.models.autoencoders.components import (\n",
        "    resnet18_decoder,\n",
        "    resnet18_encoder,\n",
        ")\n",
        "\n",
        "\n",
        "class VAE(pl.LightningModule):\n",
        "    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # encoder, decoder\n",
        "        self.encoder = resnet18_encoder(False, False)\n",
        "        self.decoder = resnet18_decoder(\n",
        "            latent_dim=latent_dim,\n",
        "            input_height=input_height,\n",
        "            first_conv=False,\n",
        "            maxpool1=False\n",
        "        )\n",
        "\n",
        "        # distribution parameters\n",
        "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
        "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
        "\n",
        "        # for the gaussian likelihood\n",
        "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "\n",
        "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
        "        scale = torch.exp(logscale)\n",
        "        mean = x_hat\n",
        "        dist = torch.distributions.Normal(mean, scale)\n",
        "\n",
        "        # measure prob of seeing image under p(x|z)\n",
        "        log_pxz = dist.log_prob(x)\n",
        "        return log_pxz.sum(dim=(1, 2, 3))\n",
        "\n",
        "    def kl_divergence(self, z, mu, std):\n",
        "        # --------------------------\n",
        "        # Monte carlo KL divergence\n",
        "        # --------------------------\n",
        "        # 1. define the first two probabilities (in this case Normal for both)\n",
        "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "\n",
        "        # 2. get the probabilities from the equation\n",
        "        log_qzx = q.log_prob(z)\n",
        "        log_pz = p.log_prob(z)\n",
        "\n",
        "        # kl\n",
        "        kl = (log_qzx - log_pz)\n",
        "        kl = kl.sum(-1)\n",
        "        return kl\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, _ = batch\n",
        "\n",
        "        # encode x to get the mu and variance parameters\n",
        "        x_encoded = self.encoder(x)\n",
        "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
        "\n",
        "        # sample z from q\n",
        "        std = torch.exp(log_var / 2)\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "        z = q.rsample()\n",
        "\n",
        "        # decoded\n",
        "        x_hat = self.decoder(z)\n",
        "\n",
        "        # reconstruction loss\n",
        "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
        "\n",
        "        # kl\n",
        "        kl = self.kl_divergence(z, mu, std)\n",
        "\n",
        "        # elbo\n",
        "        elbo = (kl - recon_loss)\n",
        "        elbo = elbo.mean()\n",
        "\n",
        "        self.log_dict({\n",
        "            'elbo': elbo,\n",
        "            'kl': kl.mean(),\n",
        "            'recon_loss': recon_loss.mean(),\n",
        "            'reconstruction': recon_loss.mean(),\n",
        "            'kl': kl.mean(),\n",
        "        })\n",
        "\n",
        "        return elbo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-002bddd9cea6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m from pl_bolts.models.autoencoders.components import (\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mresnet18_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mresnet18_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0m_HTTPS_AWS_HUB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://pl-bolts-weights.s3.us-east-2.amazonaws.com\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from pl_bolts import (  # noqa: E402\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdatamodules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/datamodules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10DataModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTinyCIFAR10DataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcityscapes_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCityscapesDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_source\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscountedExperienceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperienceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFashionMNISTDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagenetDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/datamodules/experience_source.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \"\"\"\n\u001b[1;32m     26\u001b[0m     \u001b[0mBasic\u001b[0m \u001b[0mexperience\u001b[0m \u001b[0msource\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTakes\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgenerate_batch\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_typing.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DataPipeMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         namespace.update({'type': _DEFAULT_TYPE,\n",
            "\u001b[0;32m/usr/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0m_abc_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_typing.py\u001b[0m in \u001b[0;36m_dp_init_subclass\u001b[0;34m(sub_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m                      return_hint.__origin__ == collections.abc.Iterator)):\n\u001b[1;32m    373\u001b[0m                 raise TypeError(\"Expected 'Iterator' as the return annotation for `__iter__` of {}\"\n\u001b[0;32m--> 374\u001b[0;31m                                 \", but found {}\".format(sub_cls.__name__, _type_repr(hints['return'])))\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mdata_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_hint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__args__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected 'Iterator' as the return annotation for `__iter__` of ExperienceSourceDataset, but found typing.Iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b9wS_ZCi8ldG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gOQFE3lu8mKJ"
      },
      "source": [
        "## Dataset: CIFAR10"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "id": "qYDTj9x58jWl",
        "outputId": "7deb3fe1-e169-4562-ceb8-46ae2e375d0f"
      },
      "source": [
        "from pl_bolts.datamodules import CIFAR10DataModule\n",
        "\n",
        "# for this tutorial we'll use cifar10\n",
        "cifar_10 = CIFAR10DataModule('.')"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-9c7037ab9cee>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10DataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for this tutorial we'll use cifar10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcifar_10\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCIFAR10DataModule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0m_HTTPS_AWS_HUB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://pl-bolts-weights.s3.us-east-2.amazonaws.com\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from pl_bolts import (  # noqa: E402\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdatamodules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/datamodules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10DataModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTinyCIFAR10DataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcityscapes_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCityscapesDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_source\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscountedExperienceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperienceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFashionMNISTDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagenetDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/datamodules/experience_source.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \"\"\"\n\u001b[1;32m     26\u001b[0m     \u001b[0mBasic\u001b[0m \u001b[0mexperience\u001b[0m \u001b[0msource\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTakes\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgenerate_batch\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_typing.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DataPipeMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         namespace.update({'type': _DEFAULT_TYPE,\n",
            "\u001b[0;32m/usr/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0m_abc_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_typing.py\u001b[0m in \u001b[0;36m_dp_init_subclass\u001b[0;34m(sub_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m                      return_hint.__origin__ == collections.abc.Iterator)):\n\u001b[1;32m    373\u001b[0m                 raise TypeError(\"Expected 'Iterator' as the return annotation for `__iter__` of {}\"\n\u001b[0;32m--> 374\u001b[0;31m                                 \", but found {}\".format(sub_cls.__name__, _type_repr(hints['return'])))\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mdata_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_hint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__args__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected 'Iterator' as the return annotation for `__iter__` of ExperienceSourceDataset, but found typing.Iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "HP8faq_A8te_",
        "outputId": "4f2c123d-7f2a-48b9-b374-07dd12a86e5d"
      },
      "source": [
        "pl.seed_everything(1234)\n",
        "\n",
        "vae = VAE()\n",
        "trainer = pl.Trainer(gpus=1, max_epochs=30, progress_bar_refresh_rate=10)\n",
        "trainer.fit(vae, cifar_10)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 1234\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-cad4846f1513>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed_everything\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1234\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mvae\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVAE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mtrainer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrainer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m30\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprogress_bar_refresh_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvae\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcifar_10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'VAE' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AOyp2NcV9FD5"
      },
      "source": [
        "###  look at the reconstruction."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YHQjo3Kj85yh"
      },
      "source": [
        "from matplotlib.pyplot import imshow, figure\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
        "figure(figsize=(8, 3), dpi=300)\n",
        "\n",
        "# Z COMES FROM NORMAL(0, 1)\n",
        "num_preds = 16\n",
        "p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
        "z = p.rsample((num_preds,))\n",
        "\n",
        "# SAMPLE IMAGES\n",
        "with torch.no_grad():\n",
        "    pred = vae.decoder(z.to(vae.device)).cpu()\n",
        "\n",
        "# UNDO DATA NORMALIZATION\n",
        "normalize = cifar10_normalization()\n",
        "mean, std = np.array(normalize.mean), np.array(normalize.std)\n",
        "img = make_grid(pred).permute(1, 2, 0).numpy() * std + mean\n",
        "\n",
        "# PLOT IMAGES\n",
        "imshow(img);"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tiKN7ZAs9RxA"
      },
      "source": [
        "# Full code "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 391
        },
        "id": "xizFAixT9TX0",
        "outputId": "87ff3687-1e68-4a15-fb27-f2f7f1200873"
      },
      "source": [
        "import pytorch_lightning as pl\n",
        "pl.seed_everything(1234)\n",
        "from torch import nn\n",
        "import torch\n",
        "from pl_bolts.models.autoencoders.components import (\n",
        "    resnet18_decoder,\n",
        "    resnet18_encoder,\n",
        ")\n",
        "from pl_bolts.datamodules import CIFAR10DataModule, ImagenetDataModule\n",
        "from image_plotting_callback import ImageSampler\n",
        "from argparse import ArgumentParser\n",
        "\n",
        "\n",
        "class VAE(pl.LightningModule):\n",
        "    def __init__(self, enc_out_dim=512, latent_dim=256, input_height=32):\n",
        "        super().__init__()\n",
        "\n",
        "        self.save_hyperparameters()\n",
        "\n",
        "        # encoder, decoder\n",
        "        self.encoder = resnet18_encoder(False, False)\n",
        "        self.decoder = resnet18_decoder(\n",
        "            latent_dim=latent_dim,\n",
        "            input_height=input_height,\n",
        "            first_conv=False,\n",
        "            maxpool1=False\n",
        "        )\n",
        "\n",
        "        # distribution parameters\n",
        "        self.fc_mu = nn.Linear(enc_out_dim, latent_dim)\n",
        "        self.fc_var = nn.Linear(enc_out_dim, latent_dim)\n",
        "\n",
        "        # for the gaussian likelihood\n",
        "        self.log_scale = nn.Parameter(torch.Tensor([0.0]))\n",
        "\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=1e-4)\n",
        "\n",
        "    def gaussian_likelihood(self, x_hat, logscale, x):\n",
        "        scale = torch.exp(logscale)\n",
        "        mean = x_hat\n",
        "        dist = torch.distributions.Normal(mean, scale)\n",
        "\n",
        "        # measure prob of seeing image under p(x|z)\n",
        "        log_pxz = dist.log_prob(x)\n",
        "        return log_pxz.sum(dim=(1, 2, 3))\n",
        "\n",
        "    def kl_divergence(self, z, mu, std):\n",
        "        # --------------------------\n",
        "        # Monte carlo KL divergence\n",
        "        # --------------------------\n",
        "        # 1. define the first two probabilities (in this case Normal for both)\n",
        "        p = torch.distributions.Normal(torch.zeros_like(mu), torch.ones_like(std))\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "\n",
        "        # 2. get the probabilities from the equation\n",
        "        log_qzx = q.log_prob(z)\n",
        "        log_pz = p.log_prob(z)\n",
        "\n",
        "        # kl\n",
        "        kl = (log_qzx - log_pz)\n",
        "        kl = kl.sum(-1)\n",
        "        return kl\n",
        "\n",
        "    def training_step(self, batch, batch_idx):\n",
        "        x, _ = batch\n",
        "\n",
        "        # encode x to get the mu and variance parameters\n",
        "        x_encoded = self.encoder(x)\n",
        "        mu, log_var = self.fc_mu(x_encoded), self.fc_var(x_encoded)\n",
        "\n",
        "        # sample z from q\n",
        "        std = torch.exp(log_var / 2)\n",
        "        q = torch.distributions.Normal(mu, std)\n",
        "        z = q.rsample()\n",
        "\n",
        "        # decoded\n",
        "        x_hat = self.decoder(z)\n",
        "\n",
        "        # reconstruction loss\n",
        "        recon_loss = self.gaussian_likelihood(x_hat, self.log_scale, x)\n",
        "\n",
        "        # kl\n",
        "        kl = self.kl_divergence(z, mu, std)\n",
        "\n",
        "        # elbo\n",
        "        elbo = (kl - recon_loss)\n",
        "        elbo = elbo.mean()\n",
        "\n",
        "        self.log_dict({\n",
        "            'elbo': elbo,\n",
        "            'kl': kl.mean(),\n",
        "            'recon_loss': recon_loss.mean(),\n",
        "            'reconstruction': recon_loss.mean(),\n",
        "            'kl': kl.mean(),\n",
        "        })\n",
        "\n",
        "        return elbo\n",
        "\n",
        "\n",
        "def train():\n",
        "    parser = ArgumentParser()\n",
        "    parser.add_argument('--gpus', type=int, default=None)\n",
        "    parser.add_argument('--dataset', type=str, default='cifar10')\n",
        "    args = parser.parse_args()\n",
        "\n",
        "    if args.dataset == 'cifar10':\n",
        "        dataset = CIFAR10DataModule('.')\n",
        "    if args.dataset == 'imagenet':\n",
        "        dataset = ImagenetDataModule('.')\n",
        "\n",
        "    sampler = ImageSampler()\n",
        "\n",
        "    vae = VAE()\n",
        "    trainer = pl.Trainer(gpus=args.gpus, max_epochs=20, callbacks=[sampler])\n",
        "    trainer.fit(vae, dataset)\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    train()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Global seed set to 1234\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-a5c8e66f4bb3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m from pl_bolts.models.autoencoders.components import (\n\u001b[0m\u001b[1;32m      6\u001b[0m     \u001b[0mresnet18_decoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mresnet18_encoder\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0m_HTTPS_AWS_HUB\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"https://pl-bolts-weights.s3.us-east-2.amazonaws.com\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m from pl_bolts import (  # noqa: E402\n\u001b[0m\u001b[1;32m     20\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mdatamodules\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/datamodules/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcifar10_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCIFAR10DataModule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mTinyCIFAR10DataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcityscapes_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCityscapesDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience_source\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDiscountedExperienceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperienceSource\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfashion_mnist_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFashionMNISTDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mpl_bolts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatamodules\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimagenet_datamodule\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImagenetDataModule\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/pl_bolts/datamodules/experience_source.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mExperienceSourceDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mIterableDataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \"\"\"\n\u001b[1;32m     26\u001b[0m     \u001b[0mBasic\u001b[0m \u001b[0mexperience\u001b[0m \u001b[0msource\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mTakes\u001b[0m \u001b[0ma\u001b[0m \u001b[0mgenerate_batch\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mthat\u001b[0m \u001b[0mreturns\u001b[0m \u001b[0man\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_typing.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(cls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    271\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mbase\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    272\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbase\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_DataPipeMeta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 273\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-overload]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    274\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m         namespace.update({'type': _DEFAULT_TYPE,\n",
            "\u001b[0;32m/usr/lib/python3.7/abc.py\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(mcls, name, bases, namespace, **kwargs)\u001b[0m\n\u001b[1;32m    124\u001b[0m         \"\"\"\n\u001b[1;32m    125\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 126\u001b[0;31m             \u001b[0mcls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__new__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbases\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m             \u001b[0m_abc_init\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/utils/data/_typing.py\u001b[0m in \u001b[0;36m_dp_init_subclass\u001b[0;34m(sub_cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    372\u001b[0m                      return_hint.__origin__ == collections.abc.Iterator)):\n\u001b[1;32m    373\u001b[0m                 raise TypeError(\"Expected 'Iterator' as the return annotation for `__iter__` of {}\"\n\u001b[0;32m--> 374\u001b[0;31m                                 \", but found {}\".format(sub_cls.__name__, _type_repr(hints['return'])))\n\u001b[0m\u001b[1;32m    375\u001b[0m             \u001b[0mdata_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreturn_hint\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__args__\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    376\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0missubtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msub_cls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Expected 'Iterator' as the return annotation for `__iter__` of ExperienceSourceDataset, but found typing.Iterable"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6GpPWri19WJI"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qg02W9h-9k08"
      },
      "source": [
        "### Generated samples "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtPaYx_o9ooL"
      },
      "source": [
        "from matplotlib.pyplot import imshow, figure\n",
        "import numpy as np\n",
        "from torchvision.utils import make_grid\n",
        "from pl_bolts.transforms.dataset_normalizations import cifar10_normalization\n",
        "import pytorch_lightning as pl\n",
        "import torch\n",
        "\n",
        "\n",
        "class ImageSampler(pl.Callback):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "        self.img_size = None\n",
        "        self.num_preds = 16\n",
        "\n",
        "    def on_train_epoch_end(self, trainer, pl_module, outputs):\n",
        "        figure(figsize=(8, 3), dpi=300)\n",
        "\n",
        "        # Z COMES FROM NORMAL(0, 1)\n",
        "        rand_v = torch.rand((self.num_preds, pl_module.hparams.latent_dim), device=pl_module.device)\n",
        "        p = torch.distributions.Normal(torch.zeros_like(rand_v), torch.zeros_like(rand_v))\n",
        "        z = p.rsample()\n",
        "\n",
        "        # SAMPLE IMAGES\n",
        "        with torch.no_grad():\n",
        "            pred = pl_module.decoder(z.to(pl_module.device)).cpu()\n",
        "\n",
        "        # UNDO DATA NORMALIZATION\n",
        "        normalize = cifar10_normalization()\n",
        "        mean, std = np.array(normalize.mean), np.array(normalize.std)\n",
        "        img = make_grid(pred).permute(1, 2, 0).numpy() * std + mean\n",
        "\n",
        "        # PLOT IMAGES\n",
        "        trainer.logger.experiment.add_image('img',torch.tensor(img).permute(2, 0, 1), global_step=trainer.global_step)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ixsgAxcs9pHe"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}