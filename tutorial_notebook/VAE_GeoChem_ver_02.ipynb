{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "VAE_GeoChem_ver_02.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jPRR3YBeUX0B"
      },
      "source": [
        "# Library for the Satellite images\n",
        "\n",
        "> Indented block\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ffeUiGKpmR2q",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b978f43f-2b2f-4e6f-aa12-cc7b6da77b16"
      },
      "source": [
        "!pip install earthpy"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting earthpy\n",
            "  Downloading earthpy-0.9.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.4 MB 5.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from earthpy) (2.23.0)\n",
            "Collecting rasterio\n",
            "  Downloading rasterio-1.2.10-cp37-cp37m-manylinux1_x86_64.whl (19.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.3 MB 62.1 MB/s \n",
            "\u001b[?25hCollecting geopandas\n",
            "  Downloading geopandas-0.10.2-py2.py3-none-any.whl (1.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0 MB 71.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: matplotlib>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from earthpy) (3.2.2)\n",
            "Requirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from earthpy) (1.19.5)\n",
            "Requirement already satisfied: scikit-image in /usr/local/lib/python3.7/dist-packages (from earthpy) (0.18.3)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->earthpy) (2.8.2)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->earthpy) (0.11.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->earthpy) (1.3.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.0.0->earthpy) (3.0.6)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib>=2.0.0->earthpy) (1.15.0)\n",
            "Requirement already satisfied: shapely>=1.6 in /usr/local/lib/python3.7/dist-packages (from geopandas->earthpy) (1.8.0)\n",
            "Collecting pyproj>=2.2.0\n",
            "  Downloading pyproj-3.2.1-cp37-cp37m-manylinux2010_x86_64.whl (6.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.3 MB 23.8 MB/s \n",
            "\u001b[?25hCollecting fiona>=1.8\n",
            "  Downloading Fiona-1.8.20-cp37-cp37m-manylinux1_x86_64.whl (15.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 15.4 MB 32.8 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas>=0.25.0 in /usr/local/lib/python3.7/dist-packages (from geopandas->earthpy) (1.1.5)\n",
            "Requirement already satisfied: attrs>=17 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas->earthpy) (21.2.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas->earthpy) (57.4.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas->earthpy) (2021.10.8)\n",
            "Collecting cligj>=0.5\n",
            "  Downloading cligj-0.7.2-py3-none-any.whl (7.1 kB)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Collecting click-plugins>=1.0\n",
            "  Downloading click_plugins-1.1.1-py2.py3-none-any.whl (7.5 kB)\n",
            "Requirement already satisfied: click>=4.0 in /usr/local/lib/python3.7/dist-packages (from fiona>=1.8->geopandas->earthpy) (7.1.2)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=0.25.0->geopandas->earthpy) (2018.9)\n",
            "Collecting affine\n",
            "  Downloading affine-2.3.0-py2.py3-none-any.whl (15 kB)\n",
            "Collecting snuggs>=1.4.1\n",
            "  Downloading snuggs-1.4.7-py3-none-any.whl (5.4 kB)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->earthpy) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->earthpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->earthpy) (1.24.3)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->earthpy) (1.2.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,>=4.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->earthpy) (7.1.2)\n",
            "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->earthpy) (2.6.3)\n",
            "Requirement already satisfied: imageio>=2.3.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image->earthpy) (2.4.1)\n",
            "Requirement already satisfied: scipy>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image->earthpy) (1.4.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image->earthpy) (2021.11.2)\n",
            "Installing collected packages: munch, cligj, click-plugins, snuggs, pyproj, fiona, affine, rasterio, geopandas, earthpy\n",
            "Successfully installed affine-2.3.0 click-plugins-1.1.1 cligj-0.7.2 earthpy-0.9.4 fiona-1.8.20 geopandas-0.10.2 munch-2.5.0 pyproj-3.2.1 rasterio-1.2.10 snuggs-1.4.7\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xq2r9CG2PofR",
        "outputId": "55d8e9d6-61a9-49ef-c3f1-378358bf4678"
      },
      "source": [
        "pip install pyrsgis==0.3.9"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pyrsgis==0.3.9\n",
            "  Downloading pyrsgis-0.3.9-py3-none-any.whl (13 kB)\n",
            "Installing collected packages: pyrsgis\n",
            "Successfully installed pyrsgis-0.3.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ja9_SikbUp7_"
      },
      "source": [
        "## Data Prepration and pre-processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mwkJuBxeLRf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8e6b134f-7f75-42a5-da95-a52b748fd7fa"
      },
      "source": [
        "# mnist_data = MNIST(root='./', download=True, transform=transforms.ToTensor())\n",
        "import matplotlib.pyplot as plt\n",
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromArray, imageChipsFromFile\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "\n",
        "# read the TIF file(s) (both are of different sizes - for demonstration)\n",
        "single_band_file = r'Playa_Image.tif' # this is a Landsat 5 TM image (7 bands stacked)\n",
        "# multi_band_file = r'Playa_Image.tif' # this is a Landsat 5 TM image (7 bands stacked)\n",
        "\n",
        "# create image chips\n",
        "single_band_chips = imageChipsFromFile(single_band_file, x_size=28, y_size=28)\n",
        "# multi_band_chips = imageChipsFromFile(multi_band_file, x_size=16, y_size=16)\n",
        "\n",
        "print(single_band_chips.shape)\n",
        "# print(multi_band_chips.shape)\n",
        "# print(single_band_chips[1])"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(189658, 28, 28, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hr1pdMckVXA4"
      },
      "source": [
        "## Change datatype"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yzqEYVArlgXA",
        "outputId": "e4c3e75e-ead5-486a-ffe4-88b1edffb0c7"
      },
      "source": [
        "import numpy as np\n",
        "import cv2 \n",
        "import tensorflow as tf\n",
        "\n",
        "\n",
        "# changin the type of data images \n",
        "single_band_chips        = np.rollaxis(single_band_chips, 3, 1)\n",
        "single_band_chips_float  = single_band_chips.astype(np.float32)\n",
        "\n",
        "single_band_chips_tensor = torch.as_tensor(single_band_chips_float)\n",
        "\n",
        "print(single_band_chips_tensor.dtype)\n",
        "\n",
        "print(single_band_chips.shape)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.float32\n",
            "(189658, 7, 28, 28)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kb4WliqwbIw1"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# from utils import ACTIVATION_DERIVATIVES\n",
        "import math\n",
        "import torch\n",
        "# from flows import RadialFlow, PlanarFlow\n",
        "from tqdm import tqdm\n",
        "import torch.nn.functional as F\n",
        "# from models import FCNEncoder, FCNDecoder, FlowModel\n",
        "from torchvision.datasets import MNIST\n",
        "from torchvision import transforms\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.nn import BCEWithLogitsLoss\n",
        "from matplotlib import pyplot as plt\n",
        "from scipy.special import logsumexp\n",
        "import numpy as np\n",
        "from sklearn.datasets import make_moons\n",
        "from matplotlib import collections  as mc"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "89vFZ8hPU-cW"
      },
      "source": [
        "## VAE Flow model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QC-FuVB4BqzF"
      },
      "source": [
        "from typing import List\n",
        "class FCNEncoder(nn.Module):\n",
        "    def __init__(self, hidden_sizes: List[int], dim_input: int, activation=nn.ReLU()):\n",
        "        super().__init__()\n",
        "        \n",
        "        \n",
        "        hidden_sizes = [dim_input] + hidden_sizes\n",
        "        \n",
        "        self.net = []\n",
        "\n",
        "        for i in range(len(hidden_sizes) - 1):\n",
        "            self.net.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
        "            self.net.append(nn.ReLU())\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "        \n",
        "    def forward(self, x):\n",
        "        return self.net(x)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cMmIV6CCagnw"
      },
      "source": [
        "from torch.distributions.multivariate_normal import MultivariateNormal\n",
        "\n",
        "class FlowModel(nn.Module):\n",
        "    def __init__(self, flows: List[str], D: int, activation=torch.tanh):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.prior = MultivariateNormal(torch.zeros(D), torch.eye(D))\n",
        "        self.net = []\n",
        "\n",
        "        for i in range(len(flows)):\n",
        "            layer_class = eval(flows[i])\n",
        "            self.net.append(layer_class(D, activation))\n",
        "\n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "        self.D = D\n",
        "\n",
        "\n",
        "    def forward(self, mu: torch.Tensor, log_sigma: torch.Tensor):\n",
        "        \"\"\"\n",
        "        mu: tensor with shape (batch_size, D)\n",
        "        sigma: tensor with shape (batch_size, D)\n",
        "        \"\"\"\n",
        "        sigma = torch.exp(log_sigma)\n",
        "        batch_size = mu.shape[0]\n",
        "        samples = self.prior.sample(torch.Size([batch_size]))\n",
        "        print(samples.size, sigma.shape)\n",
        "        z = samples * sigma + mu\n",
        "\n",
        "        z0 = z.clone().detach()\n",
        "        log_prob_z0 = torch.sum(\n",
        "            -0.5 * torch.log(torch.tensor(2 * math.pi)) - \n",
        "            log_sigma - 0.5 * ((z - mu) / sigma) ** 2, \n",
        "            axis=1)\n",
        "        \n",
        "        log_det = torch.zeros((batch_size,))\n",
        "        \n",
        "        for layer in self.net:\n",
        "            z, ld = layer(z)\n",
        "            log_det += ld\n",
        "\n",
        "        log_prob_zk = torch.sum(\n",
        "            -0.5 * (torch.log(torch.tensor(2 * math.pi)) + z ** 2), \n",
        "            axis=1)\n",
        "\n",
        "        return z, log_prob_z0, log_prob_zk, log_det"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MWl5ZQMXfoeq"
      },
      "source": [
        "ACTIVATION_DERIVATIVES = {\n",
        "    F.elu: lambda x: torch.ones_like(x) * (x >= 0) + torch.exp(x) * (x < 0),\n",
        "    torch.tanh: lambda x: 1 - torch.tanh(x) ** 2\n",
        "}\n",
        "\n",
        "class PlanarFlow(nn.Module):\n",
        "    def __init__(self, D, activation=torch.tanh):\n",
        "        super().__init__()\n",
        "        self.D = D\n",
        "        self.w = nn.Parameter(torch.empty(D))\n",
        "        self.b = nn.Parameter(torch.empty(1))\n",
        "        self.u = nn.Parameter(torch.empty(D))\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = ACTIVATION_DERIVATIVES[activation]\n",
        "\n",
        "        nn.init.normal_(self.w)\n",
        "        nn.init.normal_(self.u)\n",
        "        nn.init.normal_(self.b)\n",
        "\n",
        "    def forward(self, z: torch.Tensor):\n",
        "        lin = (z @ self.w + self.b).unsqueeze(1)  # shape: (B, 1)\n",
        "        f = z + self.u * self.activation(lin)  # shape: (B, D)\n",
        "        phi = self.activation_derivative(lin) * self.w  # shape: (B, D)\n",
        "        log_det = torch.log(torch.abs(1 + phi @ self.u) + 1e-4) # shape: (B,)\n",
        "        \n",
        "\n",
        "        return f, log_det\n",
        "\n",
        "\n",
        "class RadialFlow(nn.Module):\n",
        "    def __init__(self, D, activation=torch.tanh):\n",
        "        super().__init__()\n",
        "\n",
        "        self.z0 = nn.Parameter(torch.empty(D))\n",
        "        self.log_alpha = nn.Parameter(torch.empty(1))\n",
        "        self.beta = nn.Parameter(torch.empty(1))\n",
        "        self.activation = activation\n",
        "        self.activation_derivative = ACTIVATION_DERIVATIVES[activation]\n",
        "        self.D = D\n",
        "\n",
        "        nn.init.normal_(self.z0) \n",
        "        nn.init.normal_(self.log_alpha)\n",
        "        nn.init.normal_(self.beta)\n",
        "\n",
        "\n",
        "    def forward(self, z: torch.Tensor):\n",
        "        z_sub = z - self.z0\n",
        "        alpha = torch.exp(self.log_alpha)\n",
        "        r = torch.norm(z_sub)\n",
        "        h = 1 / (alpha + r)\n",
        "        f = z + self.beta * h * z_sub\n",
        "        log_det = (self.D - 1) * torch.log(1 + self.beta * h) + \\\n",
        "            torch.log(1 + self.beta * h + self.beta - self.beta * r / (alpha + r) ** 2)\n",
        "\n",
        "        return f, log_det"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rrThVTZah_O"
      },
      "source": [
        "class FCNDecoder(nn.Module):\n",
        "    def __init__(self, hidden_sizes: List[int], dim_input: int, activation=nn.ReLU()):\n",
        "        super().__init__()\n",
        "        \n",
        "        hidden_sizes = [dim_input] + hidden_sizes\n",
        "        self.net = []\n",
        "\n",
        "        for i in range(len(hidden_sizes) - 1):\n",
        "            self.net.append(nn.Linear(hidden_sizes[i], hidden_sizes[i+1]))\n",
        "            self.net.append(nn.ReLU())\n",
        "        \n",
        "        self.net = nn.Sequential(*self.net)\n",
        "\n",
        "    def forward(self, z: torch.Tensor):\n",
        "        return self.net(z)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OZcOrS_EeT1S"
      },
      "source": [
        "D = 40 # Depth (No. of channels)\n",
        "encoder = FCNEncoder(hidden_sizes=[128, 64, 2*D], dim_input=7*28*28)\n",
        "flow_model = FlowModel(flows=['PlanarFlow'] * 10, D=40)\n",
        "decoder = FCNDecoder(hidden_sizes=[64, 128, 784], dim_input=40)\n",
        "# optimizer Adam\n",
        "optimizer = optim.Adam(list(encoder.parameters()) + list(flow_model.parameters()) + list(decoder.parameters()))"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t-4VQKkJWAWf"
      },
      "source": [
        "## Training of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 658
        },
        "id": "A1VLVA_iV-yB",
        "outputId": "85cf8246-45d8-4297-d1bc-53edcd2ca882"
      },
      "source": [
        "loss_fn = BCEWithLogitsLoss()\n",
        "\n",
        "for i, X_batch in enumerate(data_loader):\n",
        "    optimizer.zero_grad()\n",
        "    out = encoder(X_batch.view(-1, 7*784).float())\n",
        "    mu, log_sigma = out[:, :40], out[:, 40:]\n",
        "    z_k, log_prob_z0, log_prob_zk, log_det = flow_model(mu, log_sigma)\n",
        "    x_hat = decoder(z_k)\n",
        "    print(x_hat.shape, )\n",
        "    \n",
        "    loss = torch.mean(log_prob_z0) + loss_fn(x_hat, X_batch.view(-1, 7*784).float()) - torch.mean(log_prob_zk) - torch.mean(log_det)\n",
        "    if i % 100 == 0:\n",
        "        print(f'Iteration {i}, loss: {loss.item()}')\n",
        "    \n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<built-in method size of Tensor object at 0x7fc4414340b0> torch.Size([32, 40])\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-d56e158b7fc9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_z0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_hat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_batch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m784\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_prob_zk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_det\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m100\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf'Iteration {i}, loss: {loss.item()}'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1100\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1101\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1102\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1103\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1104\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/loss.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, target)\u001b[0m\n\u001b[1;32m    705\u001b[0m                                                   \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m                                                   \u001b[0mpos_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m                                                   reduction=self.reduction)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mbinary_cross_entropy_with_logits\u001b[0;34m(input, target, weight, size_average, reduce, reduction, pos_weight)\u001b[0m\n\u001b[1;32m   2978\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2979\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2980\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Target size ({}) must be the same as input size ({})\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2981\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2982\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbinary_cross_entropy_with_logits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction_enum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Target size (torch.Size([32, 5488])) must be the same as input size (torch.Size([32, 784]))"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qFJS90wZayY9"
      },
      "source": [
        "out = encoder(X_batch.view(-1, 784).float())\n",
        "mu, log_sigma = out[:, :D], out[:, D:]\n",
        "z_k, log_prob_z0, log_prob_zk, log_det = flow_model(mu, log_sigma)\n",
        "x_hat = decoder(z_k)\n",
        "\n",
        "loss = torch.mean(log_prob_z0) + loss_fn(x_hat, X_batch.view(-1, 784).float()) - torch.mean(log_prob_zk) - torch.mean(log_det)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hZRa2o5KXbRi"
      },
      "source": [
        "# Trash"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HeQz_3vJdZZc"
      },
      "source": [
        "from torch.utils.data import Dataset\n",
        "import numpy as np\n",
        "import torch\n",
        "\n",
        "class BinarizedMNIST(Dataset):\n",
        "    def __init__(self, file):\n",
        "        self.data = np.load(file)\n",
        "        self.data = torch.tensor(self.data)\n",
        "\n",
        "    def __len__(self,):\n",
        "        return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return self.data[idx]\n",
        "\n",
        "# mnist_data = MNIST(root='./', download=True, transform=transforms.ToTensor())\n",
        "# data = BinarizedMNIST(single_band_chips)\n",
        "data_loader = torch.utils.data.DataLoader(single_band_chips_tensor,\n",
        "                                          batch_size=32,\n",
        "                                          shuffle=True,\n",
        "                                          num_workers=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHvdobDaAYTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32cf8f95-428b-4925-b725-89100bbe4483"
      },
      "source": [
        "from pyrsgis import raster\n",
        "from pyrsgis.ml import imageChipsFromArray, imageChipsFromFile\n",
        "import torch.nn as nn\n",
        "import torch\n",
        "# read the TIF file(s) (both are of different sizes - for demonstration)\n",
        "single_band_file = r'Playa_Image.tif'\n",
        "multi_band_file = r'Playa_Image.tif' # this is a Landsat 7 TM image (7 bands stacked)\n",
        "\n",
        "# create image chips\n",
        "single_band_chips = imageChipsFromFile(single_band_file, x_size=16, y_size=16)\n",
        "multi_band_chips  = imageChipsFromFile(multi_band_file, x_size=16, y_size=16)\n",
        "\n",
        "print(single_band_chips.shape)\n",
        "print(multi_band_chips.shape)\n",
        "# # read the files as array using pyrsgis raster.read module\n",
        "# _, single_band_array = raster.read(single_band_file)\n",
        "# _, multi_band_array = raster.read(multi_band_file)\n",
        "\n",
        "# # create image chips\n",
        "# single_band_chips = imageChipsFromArray(single_band_array, x_size=5, y_size=5)\n",
        "# multi_band_chips  = imageChipsFromArray(multi_band_array, x_size=5, y_size=5)\n",
        "\n",
        "# print(single_band_chips.shape)\n",
        "# print(multi_band_chips.shape)"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Warning! matplotlib_scalebar library not found. You may not be able to export map directly.\n",
            "(189658, 16, 16, 7)\n",
            "(189658, 16, 16, 7)\n"
          ]
        }
      ]
    }
  ]
}